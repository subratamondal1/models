{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-15T03:58:31.862972Z",
     "iopub.status.busy": "2024-11-15T03:58:31.862396Z",
     "iopub.status.idle": "2024-11-15T03:58:31.870625Z",
     "shell.execute_reply": "2024-11-15T03:58:31.869181Z",
     "shell.execute_reply.started": "2024-11-15T03:58:31.862926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import important libraries.**\n",
    "2. **Get Dataset Ready.**\n",
    "3. **Build Neural Network Classification Model.**\n",
    "4. **Pick a Loss function and Optimizer.**\n",
    "5. **Build a training loop.**\n",
    "6. **Evaluate the model.**\n",
    "7. **Optimize the model.**\n",
    "8. **Save the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import important libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T04:04:12.458728Z",
     "iopub.status.busy": "2024-11-15T04:04:12.458276Z",
     "iopub.status.idle": "2024-11-15T04:04:12.493563Z",
     "shell.execute_reply": "2024-11-15T04:04:12.491921Z",
     "shell.execute_reply.started": "2024-11-15T04:04:12.458671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataLoader in module torch.utils.data.dataloader:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |\n",
      " |  Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      " |\n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |\n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |\n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (Callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into device/CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      " |          ``None``, the default `multiprocessing context`_ of your operating system will\n",
      " |          be used. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          ``base_seed`` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers batches prefetched across all workers. (default value depends\n",
      " |          on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      " |          Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |      pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      " |          ``True``.\n",
      " |\n",
      " |\n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |\n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |\n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |\n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |\n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |\n",
      " |  .. _multiprocessing context:\n",
      " |      https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |\n",
      " |  __len__(self) -> int\n",
      " |\n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  check_worker_number_rationality(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  multiprocessing_context\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_iterator': typing.Optional[ForwardRef('_BaseDataL...\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |\n",
      " |  __parameters__ = (+T_co,)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(request=DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataLoader` class in PyTorch is used to load data in batches for training and evaluation. \n",
    "\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset=dataset,                # Source dataset to load data from\n",
    "    batch_size=1,                   # Number of samples per batch\n",
    "    shuffle=False,                  # Whether to reshuffle data at every epoch\n",
    "    sampler=None,                   # Custom sampling strategy\n",
    "    batch_sampler=None,             # Custom batch sampling strategy\n",
    "    num_workers=0,                  # Number of subprocesses for data loading (0 means main process)\n",
    "    collate_fn=None,                # Function to merge samples into batches\n",
    "    pin_memory=False,               # Copy tensors to CUDA pinned memory\n",
    "    drop_last=False,                # Drop the last incomplete batch\n",
    "    timeout=0,                      # Timeout for collecting a batch from workers\n",
    "    worker_init_fn=None,            # Function to initialize worker processes\n",
    "    multiprocessing_context=None,   # Multiprocessing context to use\n",
    ")\n",
    "```\n",
    "\n",
    "**Create a DataLoader:**\n",
    "\n",
    "```python\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "```\n",
    "\n",
    "**Iterate over the data:**\n",
    "\n",
    "```python\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIFAR10',\n",
       " 'CIFAR100',\n",
       " 'CLEVRClassification',\n",
       " 'CREStereo',\n",
       " 'Caltech101',\n",
       " 'Caltech256',\n",
       " 'CarlaStereo',\n",
       " 'CelebA',\n",
       " 'Cityscapes',\n",
       " 'CocoCaptions',\n",
       " 'CocoDetection',\n",
       " 'Country211',\n",
       " 'DTD',\n",
       " 'DatasetFolder',\n",
       " 'EMNIST',\n",
       " 'ETH3DStereo',\n",
       " 'EuroSAT',\n",
       " 'FER2013',\n",
       " 'FGVCAircraft',\n",
       " 'FakeData',\n",
       " 'FallingThingsStereo',\n",
       " 'FashionMNIST',\n",
       " 'Flickr30k',\n",
       " 'Flickr8k',\n",
       " 'Flowers102',\n",
       " 'FlyingChairs',\n",
       " 'FlyingThings3D',\n",
       " 'Food101',\n",
       " 'GTSRB',\n",
       " 'HD1K',\n",
       " 'HMDB51',\n",
       " 'INaturalist',\n",
       " 'ImageFolder',\n",
       " 'ImageNet',\n",
       " 'Imagenette',\n",
       " 'InStereo2k',\n",
       " 'KMNIST',\n",
       " 'Kinetics',\n",
       " 'Kitti',\n",
       " 'Kitti2012Stereo',\n",
       " 'Kitti2015Stereo',\n",
       " 'KittiFlow',\n",
       " 'LFWPairs',\n",
       " 'LFWPeople',\n",
       " 'LSUN',\n",
       " 'LSUNClass',\n",
       " 'MNIST',\n",
       " 'Middlebury2014Stereo',\n",
       " 'MovingMNIST',\n",
       " 'Omniglot',\n",
       " 'OxfordIIITPet',\n",
       " 'PCAM',\n",
       " 'PhotoTour',\n",
       " 'Places365',\n",
       " 'QMNIST',\n",
       " 'RenderedSST2',\n",
       " 'SBDataset',\n",
       " 'SBU',\n",
       " 'SEMEION',\n",
       " 'STL10',\n",
       " 'SUN397',\n",
       " 'SVHN',\n",
       " 'SceneFlowStereo',\n",
       " 'Sintel',\n",
       " 'SintelStereo',\n",
       " 'StanfordCars',\n",
       " 'UCF101',\n",
       " 'USPS',\n",
       " 'VOCDetection',\n",
       " 'VOCSegmentation',\n",
       " 'VisionDataset',\n",
       " 'WIDERFace',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_optical_flow',\n",
       " '_stereo_matching',\n",
       " 'caltech',\n",
       " 'celeba',\n",
       " 'cifar',\n",
       " 'cityscapes',\n",
       " 'clevr',\n",
       " 'coco',\n",
       " 'country211',\n",
       " 'dtd',\n",
       " 'eurosat',\n",
       " 'fakedata',\n",
       " 'fer2013',\n",
       " 'fgvc_aircraft',\n",
       " 'flickr',\n",
       " 'flowers102',\n",
       " 'folder',\n",
       " 'food101',\n",
       " 'gtsrb',\n",
       " 'hmdb51',\n",
       " 'imagenet',\n",
       " 'imagenette',\n",
       " 'inaturalist',\n",
       " 'kinetics',\n",
       " 'kitti',\n",
       " 'lfw',\n",
       " 'lsun',\n",
       " 'mnist',\n",
       " 'moving_mnist',\n",
       " 'omniglot',\n",
       " 'oxford_iiit_pet',\n",
       " 'pcam',\n",
       " 'phototour',\n",
       " 'places365',\n",
       " 'rendered_sst2',\n",
       " 'sbd',\n",
       " 'sbu',\n",
       " 'semeion',\n",
       " 'stanford_cars',\n",
       " 'stl10',\n",
       " 'sun397',\n",
       " 'svhn',\n",
       " 'ucf101',\n",
       " 'usps',\n",
       " 'utils',\n",
       " 'video_utils',\n",
       " 'vision',\n",
       " 'voc',\n",
       " 'widerface']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AugMix',\n",
       " 'AutoAugment',\n",
       " 'AutoAugmentPolicy',\n",
       " 'CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'ElasticTransform',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'InterpolationMode',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandAugment',\n",
       " 'RandomAdjustSharpness',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomAutocontrast',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomEqualize',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomInvert',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomPosterize',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSolarize',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " 'TrivialAugmentWide',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional_pil',\n",
       " '_functional_tensor',\n",
       " '_presets',\n",
       " 'autoaugment',\n",
       " 'functional',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get Dataset Ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_exists',\n",
       " '_check_legacy_exist',\n",
       " '_format_transform_repr',\n",
       " '_load_data',\n",
       " '_load_legacy_data',\n",
       " '_repr_indent',\n",
       " 'class_to_idx',\n",
       " 'classes',\n",
       " 'data',\n",
       " 'download',\n",
       " 'extra_repr',\n",
       " 'mirrors',\n",
       " 'processed_folder',\n",
       " 'raw_folder',\n",
       " 'resources',\n",
       " 'root',\n",
       " 'target_transform',\n",
       " 'targets',\n",
       " 'test_data',\n",
       " 'test_file',\n",
       " 'test_labels',\n",
       " 'train',\n",
       " 'train_data',\n",
       " 'train_labels',\n",
       " 'training_file',\n",
       " 'transform',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data into Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 4\n",
      "Number of workers: 2\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores: int = multiprocessing.cpu_count()\n",
    "# Use at least 1 worker, but leave 2 cores free\n",
    "num_workers: int = max(1, num_cores - 2)\n",
    "\n",
    "print(f\"Number of CPU cores: {num_cores}\")\n",
    "print(f\"Number of workers: {num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True if device.type == \"cuda\" else False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True if device.type == \"cuda\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Batch Size (BATCH_SIZE = 64)**:\n",
    "   - Why: Batch size is the number of samples processed before the model is updated.\n",
    "   - Best practice: \n",
    "     - Use powers of 2 (32, 64, 128, etc.) as they can be more efficiently processed by GPUs.\n",
    "     - 64 is a common choice that balances between speed and memory usage.\n",
    "     - Larger batch sizes generally mean faster training but may require more memory.\n",
    "\n",
    "2. **DataLoader for Training (train_dataloader)**:\n",
    "   - `dataset=train_data`: Uses the training dataset.\n",
    "   - `batch_size=BATCH_SIZE`: Processes 64 samples at a time.\n",
    "   - `shuffle=True`: \n",
    "     - Why: Shuffling helps prevent the model from learning the order of the training data.\n",
    "     - Best practice: Always shuffle training data to improve generalization and prevent overfitting.\n",
    "\n",
    "3. **DataLoader for Testing (test_dataloader)**:\n",
    "   - `dataset=test_data`: Uses the test dataset.\n",
    "   - `batch_size=BATCH_SIZE`: Keeps the same batch size as training for consistency.\n",
    "   - `shuffle=False`:\n",
    "     - Why: For test data, we typically don't need to shuffle.\n",
    "     - Best practice: Keep test data in a consistent order for reproducibility and easier error analysis.\n",
    "\n",
    "4. **Using Separate DataLoaders for Training and Testing**:\n",
    "   - Why: Training and testing phases have different requirements.\n",
    "   - Best practice: \n",
    "     - Separate data handling for training and testing allows for different configurations.\n",
    "     - It's cleaner and more modular, making the code easier to understand and maintain.\n",
    "\n",
    "5. **Consistent BATCH_SIZE**:\n",
    "   - Why: Using the same batch size for both training and testing simplifies code and ensures consistent memory usage.\n",
    "   - Best practice: \n",
    "     - Maintain consistency where possible, but be aware that you can use different batch sizes if needed (e.g., larger batch size for testing if memory allows).\n",
    "\n",
    "6. **DataLoader Usage**:\n",
    "   - Why: DataLoader provides an efficient way to load data in batches and apply transformations.\n",
    "   - Best practice:\n",
    "     - Use DataLoader instead of manually batching data.\n",
    "     - It handles **multi-threading**, **batching**, and **shuffling efficiently**.\n",
    "\n",
    "Additional Best Practices:\n",
    "- Consider using `num_workers` parameter in DataLoader for parallel data loading, especially with large datasets.\n",
    "- If using GPU, consider setting `pin_memory=True` for faster data transfer to GPU.\n",
    "- Adjust batch size based on your model size and available memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937.5\n",
      "938\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data) / BATCH_SIZE)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.25\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data) / BATCH_SIZE)\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Neural Network Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim) -> None:\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features=in_dim, out_features=n_hidden_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(in_features=n_hidden_1, out_features=n_hidden_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=n_hidden_2, out_features=out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION = 28 * 28\n",
    "N_HIDDEN_1 = 300\n",
    "N_HIDDEN_2 = 100\n",
    "OUTPUT_DIMENSION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MODEL = NeuralNetwork(\n",
    "    in_dim=INPUT_DIMENSION,\n",
    "    n_hidden_1=N_HIDDEN_1,\n",
    "    n_hidden_2=N_HIDDEN_2,\n",
    "    out_dim=OUTPUT_DIMENSION,\n",
    ")\n",
    "\n",
    "print(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of NeuralNetwork(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pick a Loss function and Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "# Calculate the Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Update parameters (weights and biases) w.r.t the Loss\n",
    "optimizer = torch.optim.Adam(params=MODEL.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(criterion)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Epoch: 1\n",
      "EPOCH: 1 / 10, LOSS: 1.4014, ACCURACY: 0.4980\n",
      "EPOCH: 1 / 10, LOSS: 1.3612, ACCURACY: 0.5034\n",
      "EPOCH: 1 / 10, LOSS: 1.3359, ACCURACY: 0.5077\n",
      "EPOCH: 1 / 10, LOSS: 1.3159, ACCURACY: 0.5099\n",
      "**************************************************\n",
      "Epoch: 2\n",
      "EPOCH: 2 / 10, LOSS: 1.2168, ACCURACY: 0.5312\n",
      "EPOCH: 2 / 10, LOSS: 1.2176, ACCURACY: 0.5302\n",
      "EPOCH: 2 / 10, LOSS: 1.2149, ACCURACY: 0.5301\n",
      "EPOCH: 2 / 10, LOSS: 1.2135, ACCURACY: 0.5292\n",
      "**************************************************\n",
      "Epoch: 3\n",
      "EPOCH: 3 / 10, LOSS: 1.0150, ACCURACY: 0.6158\n",
      "EPOCH: 3 / 10, LOSS: 1.0130, ACCURACY: 0.6161\n",
      "EPOCH: 3 / 10, LOSS: 1.0087, ACCURACY: 0.6171\n",
      "EPOCH: 3 / 10, LOSS: 1.0048, ACCURACY: 0.6188\n",
      "**************************************************\n",
      "Epoch: 4\n",
      "EPOCH: 4 / 10, LOSS: 0.9826, ACCURACY: 0.6229\n",
      "EPOCH: 4 / 10, LOSS: 0.9837, ACCURACY: 0.6229\n",
      "EPOCH: 4 / 10, LOSS: 0.9759, ACCURACY: 0.6258\n",
      "EPOCH: 4 / 10, LOSS: 0.9760, ACCURACY: 0.6264\n",
      "**************************************************\n",
      "Epoch: 5\n",
      "EPOCH: 5 / 10, LOSS: 0.9770, ACCURACY: 0.6237\n",
      "EPOCH: 5 / 10, LOSS: 0.9665, ACCURACY: 0.6280\n",
      "EPOCH: 5 / 10, LOSS: 0.9566, ACCURACY: 0.6307\n",
      "EPOCH: 5 / 10, LOSS: 0.9559, ACCURACY: 0.6308\n",
      "**************************************************\n",
      "Epoch: 6\n",
      "EPOCH: 6 / 10, LOSS: 0.9384, ACCURACY: 0.6365\n",
      "EPOCH: 6 / 10, LOSS: 0.9309, ACCURACY: 0.6386\n",
      "EPOCH: 6 / 10, LOSS: 0.9424, ACCURACY: 0.6335\n",
      "EPOCH: 6 / 10, LOSS: 0.9456, ACCURACY: 0.6316\n",
      "**************************************************\n",
      "Epoch: 7\n",
      "EPOCH: 7 / 10, LOSS: 0.9333, ACCURACY: 0.6327\n",
      "EPOCH: 7 / 10, LOSS: 0.9360, ACCURACY: 0.6341\n",
      "EPOCH: 7 / 10, LOSS: 0.9321, ACCURACY: 0.6364\n",
      "EPOCH: 7 / 10, LOSS: 0.9299, ACCURACY: 0.6371\n",
      "**************************************************\n",
      "Epoch: 8\n",
      "EPOCH: 8 / 10, LOSS: 0.9196, ACCURACY: 0.6374\n",
      "EPOCH: 8 / 10, LOSS: 0.9217, ACCURACY: 0.6382\n",
      "EPOCH: 8 / 10, LOSS: 0.9195, ACCURACY: 0.6398\n",
      "EPOCH: 8 / 10, LOSS: 0.9198, ACCURACY: 0.6394\n",
      "**************************************************\n",
      "Epoch: 9\n",
      "EPOCH: 9 / 10, LOSS: 0.9090, ACCURACY: 0.6432\n",
      "EPOCH: 9 / 10, LOSS: 0.9099, ACCURACY: 0.6432\n",
      "EPOCH: 9 / 10, LOSS: 0.9090, ACCURACY: 0.6428\n",
      "EPOCH: 9 / 10, LOSS: 0.9141, ACCURACY: 0.6406\n",
      "**************************************************\n",
      "Epoch: 10\n",
      "EPOCH: 10 / 10, LOSS: 0.8875, ACCURACY: 0.6457\n",
      "EPOCH: 10 / 10, LOSS: 0.9035, ACCURACY: 0.6413\n",
      "EPOCH: 10 / 10, LOSS: 0.9030, ACCURACY: 0.6429\n",
      "EPOCH: 10 / 10, LOSS: 0.9035, ACCURACY: 0.6434\n",
      "CPU times: user 49.1 s, sys: 23 s, total: 1min 12s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCH = 10\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print(\"*\" * 50)\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    RUNNING_LOSS = 0.0\n",
    "    RUNNING_ACCURACY = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(iterable=train_dataloader, start=1):\n",
    "        image, label = data\n",
    "        image = image.view(image.size(0), -1)\n",
    "        image = image.to(device=device)\n",
    "        label = label.to(device=device)\n",
    "\n",
    "        output = MODEL(image)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        RUNNING_LOSS += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(input=output, dim=1)\n",
    "        RUNNING_ACCURACY += (predicted == label).float().mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(\n",
    "                f\"EPOCH: {epoch+1} / {EPOCH}, LOSS: {RUNNING_LOSS/batch_idx:.4f}, ACCURACY: {RUNNING_ACCURACY/batch_idx:.4f}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0071, Test Accuracy: 0.0038\n",
      "Test Loss: 0.0123, Test Accuracy: 0.0083\n",
      "Test Loss: 0.0195, Test Accuracy: 0.0117\n",
      "Test Loss: 0.0254, Test Accuracy: 0.0160\n",
      "Test Loss: 0.0304, Test Accuracy: 0.0204\n",
      "Test Loss: 0.0370, Test Accuracy: 0.0243\n",
      "Test Loss: 0.0439, Test Accuracy: 0.0279\n",
      "Test Loss: 0.0484, Test Accuracy: 0.0325\n",
      "Test Loss: 0.0554, Test Accuracy: 0.0358\n",
      "Test Loss: 0.0605, Test Accuracy: 0.0403\n",
      "Test Loss: 0.0677, Test Accuracy: 0.0438\n",
      "Test Loss: 0.0744, Test Accuracy: 0.0482\n",
      "Test Loss: 0.0824, Test Accuracy: 0.0515\n",
      "Test Loss: 0.0886, Test Accuracy: 0.0553\n",
      "Test Loss: 0.0961, Test Accuracy: 0.0589\n",
      "Test Loss: 0.1023, Test Accuracy: 0.0631\n",
      "Test Loss: 0.1099, Test Accuracy: 0.0665\n",
      "Test Loss: 0.1167, Test Accuracy: 0.0702\n",
      "Test Loss: 0.1234, Test Accuracy: 0.0737\n",
      "Test Loss: 0.1300, Test Accuracy: 0.0774\n",
      "Test Loss: 0.1378, Test Accuracy: 0.0810\n",
      "Test Loss: 0.1443, Test Accuracy: 0.0847\n",
      "Test Loss: 0.1513, Test Accuracy: 0.0882\n",
      "Test Loss: 0.1583, Test Accuracy: 0.0917\n",
      "Test Loss: 0.1626, Test Accuracy: 0.0963\n",
      "Test Loss: 0.1672, Test Accuracy: 0.1008\n",
      "Test Loss: 0.1738, Test Accuracy: 0.1046\n",
      "Test Loss: 0.1785, Test Accuracy: 0.1094\n",
      "Test Loss: 0.1854, Test Accuracy: 0.1131\n",
      "Test Loss: 0.1914, Test Accuracy: 0.1171\n",
      "Test Loss: 0.1968, Test Accuracy: 0.1214\n",
      "Test Loss: 0.2043, Test Accuracy: 0.1248\n",
      "Test Loss: 0.2094, Test Accuracy: 0.1293\n",
      "Test Loss: 0.2150, Test Accuracy: 0.1336\n",
      "Test Loss: 0.2212, Test Accuracy: 0.1374\n",
      "Test Loss: 0.2279, Test Accuracy: 0.1411\n",
      "Test Loss: 0.2339, Test Accuracy: 0.1455\n",
      "Test Loss: 0.2412, Test Accuracy: 0.1491\n",
      "Test Loss: 0.2486, Test Accuracy: 0.1529\n",
      "Test Loss: 0.2554, Test Accuracy: 0.1565\n",
      "Test Loss: 0.2626, Test Accuracy: 0.1601\n",
      "Test Loss: 0.2687, Test Accuracy: 0.1641\n",
      "Test Loss: 0.2766, Test Accuracy: 0.1675\n",
      "Test Loss: 0.2828, Test Accuracy: 0.1714\n",
      "Test Loss: 0.2896, Test Accuracy: 0.1754\n",
      "Test Loss: 0.2982, Test Accuracy: 0.1788\n",
      "Test Loss: 0.3044, Test Accuracy: 0.1829\n",
      "Test Loss: 0.3103, Test Accuracy: 0.1870\n",
      "Test Loss: 0.3164, Test Accuracy: 0.1914\n",
      "Test Loss: 0.3220, Test Accuracy: 0.1957\n",
      "Test Loss: 0.3289, Test Accuracy: 0.1993\n",
      "Test Loss: 0.3354, Test Accuracy: 0.2032\n",
      "Test Loss: 0.3403, Test Accuracy: 0.2076\n",
      "Test Loss: 0.3465, Test Accuracy: 0.2113\n",
      "Test Loss: 0.3534, Test Accuracy: 0.2153\n",
      "Test Loss: 0.3606, Test Accuracy: 0.2191\n",
      "Test Loss: 0.3667, Test Accuracy: 0.2231\n",
      "Test Loss: 0.3739, Test Accuracy: 0.2269\n",
      "Test Loss: 0.3792, Test Accuracy: 0.2315\n",
      "Test Loss: 0.3852, Test Accuracy: 0.2359\n",
      "Test Loss: 0.3934, Test Accuracy: 0.2391\n",
      "Test Loss: 0.4000, Test Accuracy: 0.2428\n",
      "Test Loss: 0.4064, Test Accuracy: 0.2469\n",
      "Test Loss: 0.4131, Test Accuracy: 0.2508\n",
      "Test Loss: 0.4202, Test Accuracy: 0.2545\n",
      "Test Loss: 0.4265, Test Accuracy: 0.2587\n",
      "Test Loss: 0.4319, Test Accuracy: 0.2633\n",
      "Test Loss: 0.4367, Test Accuracy: 0.2678\n",
      "Test Loss: 0.4452, Test Accuracy: 0.2714\n",
      "Test Loss: 0.4511, Test Accuracy: 0.2754\n",
      "Test Loss: 0.4576, Test Accuracy: 0.2792\n",
      "Test Loss: 0.4641, Test Accuracy: 0.2830\n",
      "Test Loss: 0.4714, Test Accuracy: 0.2870\n",
      "Test Loss: 0.4782, Test Accuracy: 0.2909\n",
      "Test Loss: 0.4846, Test Accuracy: 0.2947\n",
      "Test Loss: 0.4909, Test Accuracy: 0.2989\n",
      "Test Loss: 0.4976, Test Accuracy: 0.3031\n",
      "Test Loss: 0.5026, Test Accuracy: 0.3075\n",
      "Test Loss: 0.5110, Test Accuracy: 0.3105\n",
      "Test Loss: 0.5176, Test Accuracy: 0.3148\n",
      "Test Loss: 0.5260, Test Accuracy: 0.3182\n",
      "Test Loss: 0.5339, Test Accuracy: 0.3216\n",
      "Test Loss: 0.5408, Test Accuracy: 0.3253\n",
      "Test Loss: 0.5462, Test Accuracy: 0.3297\n",
      "Test Loss: 0.5535, Test Accuracy: 0.3337\n",
      "Test Loss: 0.5611, Test Accuracy: 0.3369\n",
      "Test Loss: 0.5691, Test Accuracy: 0.3407\n",
      "Test Loss: 0.5766, Test Accuracy: 0.3445\n",
      "Test Loss: 0.5827, Test Accuracy: 0.3490\n",
      "Test Loss: 0.5891, Test Accuracy: 0.3530\n",
      "Test Loss: 0.5961, Test Accuracy: 0.3566\n",
      "Test Loss: 0.6015, Test Accuracy: 0.3609\n",
      "Test Loss: 0.6071, Test Accuracy: 0.3651\n",
      "Test Loss: 0.6146, Test Accuracy: 0.3686\n",
      "Test Loss: 0.6205, Test Accuracy: 0.3725\n",
      "Test Loss: 0.6281, Test Accuracy: 0.3759\n",
      "Test Loss: 0.6347, Test Accuracy: 0.3798\n",
      "Test Loss: 0.6404, Test Accuracy: 0.3841\n",
      "Test Loss: 0.6465, Test Accuracy: 0.3882\n",
      "Test Loss: 0.6534, Test Accuracy: 0.3919\n",
      "Test Loss: 0.6612, Test Accuracy: 0.3955\n",
      "Test Loss: 0.6684, Test Accuracy: 0.3993\n",
      "Test Loss: 0.6751, Test Accuracy: 0.4033\n",
      "Test Loss: 0.6812, Test Accuracy: 0.4072\n",
      "Test Loss: 0.6876, Test Accuracy: 0.4115\n",
      "Test Loss: 0.6927, Test Accuracy: 0.4158\n",
      "Test Loss: 0.6981, Test Accuracy: 0.4200\n",
      "Test Loss: 0.7031, Test Accuracy: 0.4248\n",
      "Test Loss: 0.7101, Test Accuracy: 0.4286\n",
      "Test Loss: 0.7168, Test Accuracy: 0.4324\n",
      "Test Loss: 0.7227, Test Accuracy: 0.4368\n",
      "Test Loss: 0.7296, Test Accuracy: 0.4406\n",
      "Test Loss: 0.7377, Test Accuracy: 0.4438\n",
      "Test Loss: 0.7434, Test Accuracy: 0.4478\n",
      "Test Loss: 0.7500, Test Accuracy: 0.4518\n",
      "Test Loss: 0.7564, Test Accuracy: 0.4556\n",
      "Test Loss: 0.7615, Test Accuracy: 0.4601\n",
      "Test Loss: 0.7687, Test Accuracy: 0.4635\n",
      "Test Loss: 0.7736, Test Accuracy: 0.4681\n",
      "Test Loss: 0.7782, Test Accuracy: 0.4726\n",
      "Test Loss: 0.7840, Test Accuracy: 0.4766\n",
      "Test Loss: 0.7907, Test Accuracy: 0.4803\n",
      "Test Loss: 0.7955, Test Accuracy: 0.4846\n",
      "Test Loss: 0.8027, Test Accuracy: 0.4884\n",
      "Test Loss: 0.8105, Test Accuracy: 0.4915\n",
      "Test Loss: 0.8162, Test Accuracy: 0.4954\n",
      "Test Loss: 0.8220, Test Accuracy: 0.4996\n",
      "Test Loss: 0.8291, Test Accuracy: 0.5034\n",
      "Test Loss: 0.8363, Test Accuracy: 0.5069\n",
      "Test Loss: 0.8437, Test Accuracy: 0.5103\n",
      "Test Loss: 0.8508, Test Accuracy: 0.5139\n",
      "Test Loss: 0.8558, Test Accuracy: 0.5182\n",
      "Test Loss: 0.8614, Test Accuracy: 0.5224\n",
      "Test Loss: 0.8688, Test Accuracy: 0.5260\n",
      "Test Loss: 0.8751, Test Accuracy: 0.5302\n",
      "Test Loss: 0.8817, Test Accuracy: 0.5338\n",
      "Test Loss: 0.8896, Test Accuracy: 0.5373\n",
      "Test Loss: 0.8962, Test Accuracy: 0.5411\n",
      "Test Loss: 0.9025, Test Accuracy: 0.5450\n",
      "Test Loss: 0.9101, Test Accuracy: 0.5489\n",
      "Test Loss: 0.9160, Test Accuracy: 0.5525\n",
      "Test Loss: 0.9230, Test Accuracy: 0.5562\n",
      "Test Loss: 0.9291, Test Accuracy: 0.5601\n",
      "Test Loss: 0.9350, Test Accuracy: 0.5643\n",
      "Test Loss: 0.9408, Test Accuracy: 0.5685\n",
      "Test Loss: 0.9469, Test Accuracy: 0.5724\n",
      "Test Loss: 0.9527, Test Accuracy: 0.5766\n",
      "Test Loss: 0.9587, Test Accuracy: 0.5807\n",
      "Test Loss: 0.9645, Test Accuracy: 0.5847\n",
      "Test Loss: 0.9713, Test Accuracy: 0.5885\n",
      "Test Loss: 0.9781, Test Accuracy: 0.5919\n",
      "Test Loss: 0.9847, Test Accuracy: 0.5957\n",
      "Test Loss: 0.9907, Test Accuracy: 0.5997\n",
      "Test Loss: 0.9964, Test Accuracy: 0.6036\n",
      "Test Loss: 1.0028, Test Accuracy: 0.6074\n",
      "Test Loss: 1.0096, Test Accuracy: 0.6111\n",
      "Test Loss: 1.0175, Test Accuracy: 0.6146\n"
     ]
    }
   ],
   "source": [
    "MODEL.eval()\n",
    "eval_loss = 0.0\n",
    "eval_accuracy = 0.0\n",
    "\n",
    "for batch_idx, data in enumerate(iterable=test_dataloader, start=1):\n",
    "    image, label = data\n",
    "    image = image.view(image.size(0), -1)\n",
    "    image = image.to(device=device)\n",
    "    label = label.to(device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = MODEL(image)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(input=output, dim=1)\n",
    "        eval_accuracy += (predicted == label).float().mean()\n",
    "    print(\n",
    "        f\"Test Loss: {eval_loss/len(test_dataloader):.4f}, Test Accuracy: {eval_accuracy/len(test_dataloader):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "images, labels = next(iter(test_dataloader))\n",
    "images = images.reshape(-1, 28 * 28).to(device=device)\n",
    "labels = labels.to(device=device)\n",
    "outputs = MODEL(images)\n",
    "\n",
    "_, predicted = torch.max(input=outputs, dim=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))  # 1 row, 5 columns\n",
    "for i in range(5):\n",
    "    # Convert PyTorch tensor to a 2D list (which matplotlib can handle)\n",
    "    img_list = images[i].reshape(28, 28).cpu().tolist()\n",
    "    axs[i].imshow(img_list, cmap=\"gray\")\n",
    "    axs[i].set_title(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=MODEL.state_dict(), f=\"./models/NeuralNetworkModel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "models-wPjj_xAa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
